{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydantic import BaseModel\n",
    "import joblib\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "from datetime import datetime, timedelta\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# 2. Class which describes a single flower measurements\n",
    "class SearchedTweets(BaseModel):\n",
    "    topic_name: str\n",
    "    username: str\n",
    "    date_init: str\n",
    "    date_end: str\n",
    "    limit_number_search: int\n",
    "    \n",
    "\n",
    "\n",
    "# 3. Class for training the model and making predictions\n",
    "class SenimentModel:\n",
    "    # 6. Class constructor, loads the dataset and loads the model\n",
    "    #    if exists. If not, calls the _train_model method and \n",
    "    #    saves the model\n",
    "    def __init__(self):\n",
    "        self._model_path = '../model/saved_model/blstm_model'\n",
    "        self._tokenizer_path = '../model/saved_tokenizer/tokenizer.pickle'\n",
    "\n",
    "        try:\n",
    "            # Load the saved tokenizer\n",
    "            self.tokenizer = Tokenizer()\n",
    "            with open(self._tokenizer_path, 'rb') as handle:\n",
    "                self.tokenizer = pickle.load(handle)\n",
    "            # Load the saved model\n",
    "            self.model = load_model(self._model_path)\n",
    "\n",
    "        except Exception as e: print(e)\n",
    "\n",
    "    def _scrapp_tweet(self, topic_name=None, username=None, date_init=None, date_end=None, limit_number_search=None):\n",
    "        # Creating list to append tweet data to\n",
    "        attributes_container = []\n",
    "\n",
    "        if not limit_number_search: limit_number_search = 100\n",
    "        if username: username = 'from:' + username\n",
    "        if date_init: date_init = 'since:' + date_init\n",
    "        if date_end: \n",
    "            # convert the string to a datetime object\n",
    "            date = datetime.strptime(date_end, '%Y-%m-%d')\n",
    "\n",
    "            # add one day\n",
    "            new_date = date + timedelta(days=1)\n",
    "\n",
    "            # convert the new date back to a string\n",
    "            new_date_str = datetime.strftime(new_date, '%Y-%m-%d')\n",
    "            \n",
    "            date_end = 'until:' + new_date_str\n",
    "\n",
    "        list_kwords = [username, topic_name, date_init, date_end]\n",
    "\n",
    "        search_sentence = \" \".join([s for s in list_kwords if s])\n",
    "        # Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "        for i,tweet in enumerate(sntwitter.TwitterSearchScraper(search_sentence).get_items()):\n",
    "            if i > (limit_number_search - 1):\n",
    "                break\n",
    "            attributes_container.append([tweet.user.username, tweet.date, tweet.likeCount, tweet.sourceLabel, tweet.content])\n",
    "    \n",
    "        # Creating a dataframe to load the list\n",
    "        tweets_df = pd.DataFrame(attributes_container, columns=[\"User\", \"Date Created\", \"Number of Likes\", \"Source of Tweet\", \"Tweet\"])\n",
    "        # Applying the cleaning function to both test and training datasets\n",
    "        tweets_df[\"Tweet\"] = tweets_df[\"Tweet\"].apply(lambda x: clean_text(x))\n",
    "        # Applying the function to both test and training datasets\n",
    "        tweets_df[\"Tweet\"] = tweets_df[\"Tweet\"].apply(lambda x: remove_emoji(x))\n",
    "        return tweets_df[[\"Date Created\", \"Number of Likes\", \"Tweet\"]]\n",
    "\n",
    "\n",
    "    def _preprocess_tweet(self, tweets_df: pd.DataFrame):\n",
    "        tweets = tweets_df['Tweet'].values\n",
    "\n",
    "        input_sequence = self.tokenizer.texts_to_sequences(tweets)\n",
    "        padded_sequence = pad_sequences(input_sequence, maxlen=280, truncating='post')\n",
    "        return padded_sequence\n",
    "\n",
    "\n",
    "    def predict(self, topic_name=None, username=None, date_init=None, date_end=None, limit_number_search=None):\n",
    "        tweets_df = self._scrapp_tweet(topic_name, username, date_init, date_end, limit_number_search)\n",
    "        processed_tweet = self._preprocess_tweet(tweets_df)\n",
    "\n",
    "        # predict the sentiment probabilities\n",
    "        sentiment_probs = self.model.predict(processed_tweet)\n",
    "\n",
    "        # create a new column with rounded values\n",
    "        tweets_df['Probability'] = sentiment_probs\n",
    "        # create a new column with 'Positive' or 'Negative' values\n",
    "        tweets_df['Sentiment'] = tweets_df['Probability'].apply(lambda x: 'Positive' if round(x) == 1 else 'Negative')\n",
    "\n",
    "        return tweets_df[[\"Date Created\", \"Number of Likes\", \"Tweet\", \"Sentiment\", \"Probability\"]]\n",
    "    \n",
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
    "    text = re.sub(\"#[A-Za-z0-9_]+\",\"\", text)\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SenimentModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Local\\Temp\\ipykernel_24396\\2085170050.py:72: DeprecatedFeatureWarning: content is deprecated, use rawContent instead\n",
      "  attributes_container.append([tweet.user.username, tweet.date, tweet.likeCount, tweet.sourceLabel, tweet.content])\n"
     ]
    }
   ],
   "source": [
    "tweets_df = model._scrapp_tweet(topic_name='League of Legends', username='riotgames', date_end='2023-03-02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Created</th>\n",
       "      <th>Number of Likes</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-28 20:26:15+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>were happy you enjoyed yourself ü•∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-17 21:17:15+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>you did this dragon god justice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-16 22:23:57+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>the expressions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-10 00:07:34+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>were happy to have you ü§ç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-03 23:14:50+00:00</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2019-10-23 17:01:10+00:00</td>\n",
       "      <td>1061</td>\n",
       "      <td>emiru there is nothing like seeing league ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2019-10-21 21:54:43+00:00</td>\n",
       "      <td>18</td>\n",
       "      <td>thanks for the visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2019-10-17 00:06:51+00:00</td>\n",
       "      <td>51</td>\n",
       "      <td>as the sign says behind you thank you for ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2019-10-17 00:05:38+00:00</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2019-10-16 23:23:33+00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>so uh did we surprise you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date Created  Number of Likes  \\\n",
       "0  2023-02-28 20:26:15+00:00                1   \n",
       "1  2023-02-17 21:17:15+00:00                4   \n",
       "2  2023-02-16 22:23:57+00:00                2   \n",
       "3  2023-02-10 00:07:34+00:00                2   \n",
       "4  2023-02-03 23:14:50+00:00                7   \n",
       "..                       ...              ...   \n",
       "95 2019-10-23 17:01:10+00:00             1061   \n",
       "96 2019-10-21 21:54:43+00:00               18   \n",
       "97 2019-10-17 00:06:51+00:00               51   \n",
       "98 2019-10-17 00:05:38+00:00               10   \n",
       "99 2019-10-16 23:23:33+00:00               11   \n",
       "\n",
       "                                                Tweet  \n",
       "0                   were happy you enjoyed yourself ü•∞  \n",
       "1                    you did this dragon god justice   \n",
       "2                                    the expressions   \n",
       "3                            were happy to have you ü§ç  \n",
       "4                                                      \n",
       "..                                                ...  \n",
       "95    emiru there is nothing like seeing league ch...  \n",
       "96                              thanks for the visit   \n",
       "97    as the sign says behind you thank you for ma...  \n",
       "98                                                     \n",
       "99                         so uh did we surprise you   \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_json = tweets_df.to_json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_json = \"{\\\"Date Created\\\":{\\\"0\\\":1677615975000,\\\"1\\\":1676668635000,\\\"2\\\":1676586237000,\\\"3\\\":1675987654000,\\\"4\\\":1675466090000},\\\"Number of Likes\\\":{\\\"0\\\":1,\\\"1\\\":4,\\\"2\\\":2,\\\"3\\\":2,\\\"4\\\":7},\\\"Tweet\\\":{\\\"0\\\":\\\"  were happy you enjoyed yourself \\\\ud83e\\\\udd70\\\",\\\"1\\\":\\\"  you did this dragon god justice \\\",\\\"2\\\":\\\"    the expressions \\\",\\\"3\\\":\\\"  were happy to have you \\\\ud83e\\\\udd0d\\\",\\\"4\\\":\\\"  \\\"},\\\"Sentiment\\\":{\\\"0\\\":\\\"Positive\\\",\\\"1\\\":\\\"Negative\\\",\\\"2\\\":\\\"Negative\\\",\\\"3\\\":\\\"Positive\\\",\\\"4\\\":\\\"Negative\\\"},\\\"Probability\\\":{\\\"0\\\":0.8692666888,\\\"1\\\":0.1586038619,\\\"2\\\":1.815350486e-31,\\\"3\\\":0.8309826851,\\\"4\\\":0.4170664549}}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Date Created\":{\"0\":1677615975000,\"1\":1676668635000,\"2\":1676586237000,\"3\":1675987654000,\"4\":1675466090000},\"Number of Likes\":{\"0\":1,\"1\":4,\"2\":2,\"3\":2,\"4\":7},\"Tweet\":{\"0\":\"  were happy you enjoyed yourself \\\\ud83e\\\\udd70\",\"1\":\"  you did this dragon god justice \",\"2\":\"    the expressions \",\"3\":\"  were happy to have you \\\\ud83e\\\\udd0d\",\"4\":\"  \"},\"Sentiment\":{\"0\":\"Positive\",\"1\":\"Negative\",\"2\":\"Negative\",\"3\":\"Positive\",\"4\":\"Negative\"},\"Probability\":{\"0\":0.8692666888,\"1\":0.1586038619,\"2\":1.815350486e-31,\"3\":0.8309826851,\"4\":0.4170664549}}'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_df = pd.read_json(tw_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Created</th>\n",
       "      <th>Number of Likes</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1677615975000</td>\n",
       "      <td>1</td>\n",
       "      <td>were happy you enjoyed yourself ü•∞</td>\n",
       "      <td>Positive</td>\n",
       "      <td>8.692667e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1676668635000</td>\n",
       "      <td>4</td>\n",
       "      <td>you did this dragon god justice</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1.586039e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1676586237000</td>\n",
       "      <td>2</td>\n",
       "      <td>the expressions</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1.815350e-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1675987654000</td>\n",
       "      <td>2</td>\n",
       "      <td>were happy to have you ü§ç</td>\n",
       "      <td>Positive</td>\n",
       "      <td>8.309827e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1675466090000</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>Negative</td>\n",
       "      <td>4.170665e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Date Created  Number of Likes                                Tweet  \\\n",
       "0  1677615975000                1    were happy you enjoyed yourself ü•∞   \n",
       "1  1676668635000                4     you did this dragon god justice    \n",
       "2  1676586237000                2                     the expressions    \n",
       "3  1675987654000                2             were happy to have you ü§ç   \n",
       "4  1675466090000                7                                        \n",
       "\n",
       "  Sentiment   Probability  \n",
       "0  Positive  8.692667e-01  \n",
       "1  Negative  1.586039e-01  \n",
       "2  Negative  1.815350e-31  \n",
       "3  Positive  8.309827e-01  \n",
       "4  Negative  4.170665e-01  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "\n",
    "attributes_container = []\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper(\"from:sjkbsdbgsibsbiaifbaisbf\").get_items()):\n",
    "    if i > 100:\n",
    "        break\n",
    "    attributes_container.append([tweet.user.username, tweet.date, tweet.likeCount, tweet.sourceLabel, tweet.content])\n",
    "tweets_df = pd.DataFrame(attributes_container, columns=[\"User\", \"Date Created\", \"Number of Likes\", \"Source of Tweet\", \"Tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
